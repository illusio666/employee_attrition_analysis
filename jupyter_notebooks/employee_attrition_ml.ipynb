{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62341c2a",
   "metadata": {},
   "source": [
    "# Using machine learning to identity clusters of 'at risk' employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "988af030",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1 - Import necessary libraries\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import joblib  # for saving an ml model\n",
    "\n",
    "# Robust data-file finder and loader (uses a relative path for reading)\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf06867",
   "metadata": {},
   "source": [
    "Identifying causes of attrition and enabling the business to identify different groups of 'at risk' employees is key. \n",
    "\n",
    "This notebook will create a model that will assess the 1400 rows of data currently available (split by 'train' and 'test' groups) to identify if there are logical groupings of exited staff, to enable future departures to be anticipated and, if desired, attempts made to retain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce3933",
   "metadata": {},
   "source": [
    "### Step 1 - import the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4534960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 39 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Age                           1470 non-null   int64  \n",
      " 1   Attrition                     1470 non-null   object \n",
      " 2   BusinessTravel                1470 non-null   object \n",
      " 3   DailyRate                     1470 non-null   int64  \n",
      " 4   Department                    1470 non-null   object \n",
      " 5   DistanceFromHome              1470 non-null   int64  \n",
      " 6   Education                     1470 non-null   object \n",
      " 7   EducationField                1470 non-null   object \n",
      " 8   EnvironmentSatisfaction       1470 non-null   object \n",
      " 9   Gender                        1470 non-null   object \n",
      " 10  HourlyRate                    1470 non-null   int64  \n",
      " 11  JobInvolvement                1470 non-null   object \n",
      " 12  JobLevel                      1470 non-null   int64  \n",
      " 13  JobRole                       1470 non-null   object \n",
      " 14  JobSatisfaction               1470 non-null   object \n",
      " 15  MaritalStatus                 1470 non-null   object \n",
      " 16  MonthlyIncome                 1470 non-null   int64  \n",
      " 17  MonthlyRate                   1470 non-null   int64  \n",
      " 18  NumCompaniesWorked            1470 non-null   int64  \n",
      " 19  OverTime                      1470 non-null   object \n",
      " 20  PercentSalaryHike             1470 non-null   int64  \n",
      " 21  PerformanceRating             1470 non-null   object \n",
      " 22  RelationshipSatisfaction      1470 non-null   object \n",
      " 23  StockOptionLevel              1470 non-null   int64  \n",
      " 24  TotalWorkingYears             1470 non-null   int64  \n",
      " 25  TrainingTimesLastYear         1470 non-null   int64  \n",
      " 26  WorkLifeBalance               1470 non-null   object \n",
      " 27  YearsAtCompany                1470 non-null   int64  \n",
      " 28  YearsInCurrentRole            1470 non-null   int64  \n",
      " 29  YearsSinceLastPromotion       1470 non-null   int64  \n",
      " 30  YearsWithCurrManager          1470 non-null   int64  \n",
      " 31  RoleTenureRatio               1470 non-null   float64\n",
      " 32  ManagerTenureRatio            1470 non-null   float64\n",
      " 33  IncomeTenureRatio             1470 non-null   float64\n",
      " 34  IncomeTotalWorkRatio          1470 non-null   float64\n",
      " 35  RoleTenureRatio_was_nan       1470 non-null   int64  \n",
      " 36  ManagerTenureRatio_was_nan    1470 non-null   int64  \n",
      " 37  IncomeTenureRatio_was_nan     1470 non-null   int64  \n",
      " 38  IncomeTotalWorkRatio_was_nan  1470 non-null   int64  \n",
      "dtypes: float64(4), int64(20), object(15)\n",
      "memory usage: 448.0+ KB\n",
      "None\n",
      "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
      "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
      "1   49        No  Travel_Frequently        279  Research & Development   \n",
      "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
      "3   33        No  Travel_Frequently       1392  Research & Development   \n",
      "4   27        No      Travel_Rarely        591  Research & Development   \n",
      "\n",
      "   DistanceFromHome        Education EducationField EnvironmentSatisfaction  \\\n",
      "0                 1        2-College  Life Sciences                2-Medium   \n",
      "1                 8  1-Below College  Life Sciences                  3-High   \n",
      "2                 2        2-College          Other             4-Very High   \n",
      "3                 3         4-Master  Life Sciences             4-Very High   \n",
      "4                 2  1-Below College        Medical                   1-Low   \n",
      "\n",
      "   Gender  ...  YearsSinceLastPromotion YearsWithCurrManager  RoleTenureRatio  \\\n",
      "0  Female  ...                        0                    5             0.67   \n",
      "1    Male  ...                        1                    7             0.70   \n",
      "2    Male  ...                        0                    0             0.00   \n",
      "3  Female  ...                        3                    0             0.88   \n",
      "4    Male  ...                        2                    2             1.00   \n",
      "\n",
      "  ManagerTenureRatio IncomeTenureRatio IncomeTotalWorkRatio  \\\n",
      "0               0.83            998.83               749.12   \n",
      "1               0.70            513.00               513.00   \n",
      "2               0.00              0.00               298.57   \n",
      "3               0.00            363.62               363.62   \n",
      "4               1.00           1734.00               578.00   \n",
      "\n",
      "   RoleTenureRatio_was_nan  ManagerTenureRatio_was_nan  \\\n",
      "0                        0                           0   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           0   \n",
      "4                        0                           0   \n",
      "\n",
      "   IncomeTenureRatio_was_nan IncomeTotalWorkRatio_was_nan  \n",
      "0                          0                            0  \n",
      "1                          0                            0  \n",
      "2                          0                            0  \n",
      "3                          0                            0  \n",
      "4                          0                            0  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data using an explicit relative path\n",
    "df = pd.read_csv('../Data files/HR_Attrition_Cleaned.csv')\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69513b",
   "metadata": {},
   "source": [
    "### Step 2 - Data preparation for ML\n",
    "\n",
    "Next, as we're working with a mix of numeric and string columns, we'll identify the data types in readiness to encoding. But our target column (Attrition) needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cca4b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"Attrition\"\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Remove target from both lists if present\n",
    "numeric_cols = [col for col in numeric_cols if col != target_col]\n",
    "categorical_cols = [col for col in categorical_cols if col != target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24820435",
   "metadata": {},
   "source": [
    "Now we need to split our data into a training set and then a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af75ecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1029, 38) (1029,)\n",
      "Test shape: (441, 38) (441,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=101\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e8f32",
   "metadata": {},
   "source": [
    "Now we need to pre-process our data to allow the pipeline to handle those different data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eaef6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", StandardScaler(), numeric_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ada56c",
   "metadata": {},
   "source": [
    "### Step 3 - build pipeline\n",
    "\n",
    "Now the pipeline model can be built. We are using Random Forest because it handles mixed data sets, can identify complex interactions (ydata-profiling already identified that there's no single strong correlation for Attrition) and can rank importance. It is also more appropriate for 'imbalanced' data sets, like attrition, where values are more likely to be in the 'still employed' side of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f32cac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff1f22",
   "metadata": {},
   "source": [
    "Now we train the model using the 'train' data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "addd1737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.8526077097505669\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model score:\", pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105251b",
   "metadata": {},
   "source": [
    "While a score of 0.85 indicates a strong accuracy rate, this can sometimes be misleading if there is not an even split in the data. So we need to understand if the prediction of 'Yes' to attrition is strong, rather than a mean score across the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12806def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attrition\n",
       "No     0.838776\n",
       "Yes    0.161224\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the split of data between yes and no for attrition\n",
    "df[\"Attrition\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab409cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.86      0.98      0.92       371\n",
      "         Yes       0.65      0.16      0.25        70\n",
      "\n",
      "    accuracy                           0.85       441\n",
      "   macro avg       0.75      0.57      0.59       441\n",
      "weighted avg       0.83      0.85      0.81       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuracy for each of the two groups\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431a474",
   "metadata": {},
   "source": [
    "The model is right 65% of the time when it predicts attrition to be Yes (precision) but it's only picking up 16% of the actual leavers (recall).\n",
    "\n",
    "So we need to try to fine tune the model to improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d03a31",
   "metadata": {},
   "source": [
    "### Step 4 - improve outcomes\n",
    "\n",
    "We have several options to refine the model. We'll look at two of those options:\n",
    "\n",
    "1) weight the mistakes more strongly, to take attrition more seriously, and\n",
    "2) change the balance of Yes and No cases (create some fake-but-similar Yes rows or remove some of the No rows).\n",
    "\n",
    "We'll do both of these, with 2) first to improve the training data, followed by 1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
